# TitanicProject

**Project Overview**
This project demonstrates an end-to-end MLOps pipeline for a classification task using the Titanic dataset. It covers distributed data preprocessing, model training with Spark MLlib, experiment tracking with MLflow, and a basic model serving API. The pipeline is designed to be scalable, automated, and reproducible, addressing key challenges in real-world machine learning operations.

**Prerequisites**
To run this project, you need to have the following installed on your system:

-Docker Desktop (with WSL2 backend): This is essential for running the project in a containerized environment, which ensures consistency and reproducibility.

-Git: For cloning the repository.

-Conda: To manage the project's Python environment.

-DVC (Data Version Control): For managing and versioning the dataset.
